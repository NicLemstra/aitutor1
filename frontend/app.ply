import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.document_loaders import UnstructuredPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import ConversationalRetrievalChain
import tempfile
import os

st.set_page_config(page_title="ğŸ“˜ AI Tutor", layout="wide")
st.title("ğŸ“š AI Tutor - Multi-Course Mode")

# ---------------------- Session State Setup ----------------------
if "courses" not in st.session_state:
    st.session_state.courses = {}

if "current_course" not in st.session_state:
    st.session_state.current_course = None

# ---------------------- Course Selection ----------------------
course_names = list(st.session_state.courses.keys())
selected_course = st.selectbox("Select a course", course_names + ["â• Create new course"])

if selected_course == "â• Create new course":
    new_course_name = st.text_input("Enter new course name")
    if st.button("Create Course") and new_course_name:
        st.session_state.current_course = new_course_name
        st.session_state.courses[new_course_name] = {
            "chain": None,
            "chat_history": []
        }
        st.experimental_rerun()
else:
    st.session_state.current_course = selected_course

course = st.session_state.courses.get(st.session_state.current_course)

# ---------------------- Upload & Train PDF ----------------------
if course:
    st.header(f"ğŸ“˜ Course: {st.session_state.current_course}")
    if not course["chain"]:
        uploaded_file = st.file_uploader("Upload a class PDF", type=["pdf"])
        if uploaded_file:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.read())
                tmp_path = tmp_file.name

            st.success("âœ… PDF uploaded. Preparing tutor...")

            loader = UnstructuredPDFLoader(tmp_path)
            docs = loader.load()
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
chunks = splitter.split_documents(docs)
embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_documents(chunks, embeddings)
llm = ChatOpenAI(model_name="gpt-4", temperature=0)

# Create the conversational chain
course["chain"] = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=vectorstore.as_retriever()
)

# Extract full text for summary & quiz generation
full_text = "\n\n".join([doc.page_content for doc in docs])[:6000]  # limit tokens

# Summary
with st.spinner("ğŸ” Generating summary..."):
    summary_prompt = "Summarize this document for a student in 5 bullet points."
    summary_llm = ChatOpenAI(model_name="gpt-4", temperature=0)
    summary = summary_llm.predict(f"{summary_prompt}\n\n{full_text}")
    course["summary"] = summary

# Quiz
with st.spinner("ğŸ§  Generating quiz questions..."):
    quiz_prompt = "Write 5 quiz questions (with answers) based on this document:"
    quiz = summary_llm.predict(f"{quiz_prompt}\n\n{full_text}")
    course["quiz"] = quiz

# Glossary
with st.spinner("ğŸ“š Extracting key terms..."):
    glossary_prompt = "List 5 key terms or concepts from this document with short definitions:"
    glossary = summary_llm.predict(f"{glossary_prompt}\n\n{full_text}")
    course["glossary"] = glossary

st.success("ğŸ“ Tutor, summary, quiz, and glossary ready!")
    else:
if "summary" in course:
    st.subheader("ğŸ“ Course Summary")
    st.markdown(course["summary"])
if "summary" in course:
    st.subheader("ğŸ“ Course Summary")
    st.markdown(course["summary"])
    if st.button("ğŸ”„ Regenerate Summary"):
        with st.spinner("Regenerating summary..."):
            full_text = "\n\n".join([doc.page_content for doc in docs])[:6000]
            summary_prompt = "Summarize this document for a student in 5 bullet points."
            summary = ChatOpenAI(model_name="gpt-4", temperature=0).predict(
                f"{summary_prompt}\n\n{full_text}"
            )
            course["summary"] = summary
        st.experimental_rerun()

if "quiz" in course:
    st.subheader("â“ Practice Quiz")
    st.markdown(course["quiz"])

if "glossary" in course:
    st.subheader("ğŸ“š Key Terms")
    st.markdown(course["glossary"])
        st.subheader("ğŸ’¬ Chat With Your Tutor")
        query = st.text_input("Ask a question:")
        if query:
            result = course["chain"]({
                "question": query,
                "chat_history": course["chat_history"]
            })
            course["chat_history"].append((query, result["answer"]))

        for q, a in course["chat_history"]:
            st.markdown(f"**You:** {q}")
            st.markdown(f"**Tutor:** {a}")
